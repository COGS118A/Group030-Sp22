{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "- Joshua Garcia\n",
    "- Rey Mendoza\n",
    "- Ryan Burden\n",
    "- Terence Ting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The purpose of this project is to select and optimize a model that is appropriate for the task of classifying pictures of food with varying degrees of noise into food categories. Our models will be evaluated by classification error metrics. The datapoint, 'food101' consists 101,000 labeled images of food. Each datapoint has the dimensionality (256, 256, 3), as each image is 256 x 256 in resolution has has three color channels. We will be training supervised classification methods such as random forests, as well as neural network architectures such as ResNet50 on these images and evaluating their performance on the test set. The optimal hyperparameters and architecture of our model will be determied with cross-validated error. Finally, test set precision and recall will be used to evlauate the performance of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "This dataset of food images was previously used by Bossard <i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote) in a similar food image classification study where they sought to automatically recognize pictured dishes using Random Forests to discriminate between key areas of the images, allowing them to classify different parts of the image simultaneously. There, they detailed how classical approaches to image classification use interest point descriptors before being transformed into a vectorial-representation of the image and using Support Vector Machines for classification. They also bring to attention the novel technique of classifying certain objects or parts of an image by using Deformable Part-based Models for object detection <a name=\"felzenszwalb\"></a>[<sup>[2]</sup>](#felzenszwalbnote).\n",
    "\n",
    "Focusing instead on the food recognition part of the paper, they reference a paper by Joutou <a name = \"joutou\"></a>[<sup>[3]</sup>](#joutounote) which used a private dataset of Japanese dishes for training and classification whereas Kawano <a name = \"kawano\"></a>[<sup>[4]</sup>](#kawanonote), while also using a private dataset of Chinese dishes, made use of DPM to locally pool features to aid in food categorization. Furthermore, in a paper by Yang <i>et al</i>. <a name = \"yang\"></a>[<sup>[5]</sup>](#yangnote), the goal was to use images of food and learn the spatial relationships between the different ingredients in the dish using pairwise features. Bossard et al. commented that this particular approach would only be feasible for meals with a standardized layout. \n",
    "\n",
    "As presented by Bossard <i>et al</i>.<i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote), the problem of food classification becomes increasingly relevant given the “abundance of food photography in social networks”. From mundane tasks such as the organization of a collection of food photos to tasks such as helping patients with diabetes easily track and count their calorie intake <i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote), classifying images of food has many use cases in today’s society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "For those not well-versed in the culinary arts, identifying and naming different dishes, especially with the prevalence of food across social media, may serve as a challenge. We aim to train some machine learning algorithm to recognize and classify the images of food in this repository so that the algorithm can, with some level of accuracy, correctly classify new images that are input by the user. The success of this machine learning algorithm would be determined by the proportion of images it correctly classifies.\n",
    "\n",
    "In contrast, others might use image classification to perform facial recognition or facial detection in an image which essentially uses features to make decisions on the given image. In our case we would use similar methods to try to detect features from images of food. \n",
    "\n",
    "This problem also faces the issue of non-linearity. Since this is an image which has various forms of noise as well as images taken from different angles and shapes we face the consequence of non-linear data. Meaning our model complexity would increase due to the variable extra handling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "We plan on using the Food-101 Dataset. \n",
    "\n",
    "- https://www.kaggle.com/datasets/dansbecker/food-101?select=food-101.zip\n",
    "- 101 Different food categories, each category of food has various different variations of that food image. In total there are 101,000 images each photo of size 512 pixels. We are given 750 training images as well.\n",
    "- An observation is a photo of a specific type of food\n",
    "- Each category of food is considered its own variable, the photos are stored by their category of food and labled the count of which photo they are. ie.(Pizza_1).\n",
    "- Transformations and images are already centered and properly organized and labled such that we won’t need to take extra special data cleaning to manage this dataset. That said, we do plan on adding extra distortion to these images to test our algorithms accuracy with images that have distortion such as gaussian blur, extra noise, or discoloration.\n",
    "-Each image class will have the same number of images compared to every other class, that is 1000 images per class in order to ensure that each image class is balanced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "Our proposed solution would be to use a deep learning model, Support Vector Machines, and K-Nearest Neighbors in three different image classification models and compare their overall performance when trained on our repository of photos. The paper we based our project on instead uses a Random Forests model to achieve an accuracy of 54-58%. \n",
    "\n",
    "We are considering applying ResNet50, which is a deep learning model with that is used for image classification with relatively high accuracy. Using 48 convolution layers and pretrained over 1 million images from the imageNet database allows the model to classify images into 1000 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "The best evaluation metrics to perform when doing classification are accuracy, precision, and recall. We will find accuracy by dividing the number of predicted class by the number of actual correct in the class. This will give us how well our model predicts the right answer. The precision metric will allow us to see if our model is making too many false positives or false negatives, and is given by dividing the number of true positive by the total predicted positive. Then we use recall metric to find the true predicted positive divided by the total actual positive. We would also like to use an F1 score so that we can see which model contains the highest precision and highest recall to evaluate each model. We can also use the AUC-ROC method where we plot the true positive rate vs the false positive rate and get the area under the curve. The higher the area we get, the better the overall model performance. We can then compare the area amongst the models we select for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "Disclaimer*\n",
    "We have not done any analysis of model accuracy with our dataset yet, this is due to the fact that we need to perform more research on how to impliment the models on image data, we also want to ensure that our models are done correctly to make sure our results come out accurate. \n",
    "\n",
    "We plan on meeting with TA's to further discuss the correct course of action to help us design our models. \n",
    "\n",
    "Although we have not done model accuracy testing yet, we have completed our EDA and we have designed our features that we expect to use from our data. and we have designed our validation accuracy algorithm as shown below. We just need to impliment the models to provide data to our validation code. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling/ Cleaning\n",
    "\n",
    "This code below is to scale each image to the size 256 x 256. That way we are able to ensure that all of our data is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ScaledDir = \"food-101/food-101/imagesScaled/\"\n",
    "\n",
    "#for cat in categories:\n",
    "#    try:\n",
    "#        os.makedirs(ScaledDir + '/' + cat + '/')\n",
    "#    except:\n",
    "#        donothing = 0\n",
    "#Scale Images\n",
    "#from PIL import Image, ImageStat\n",
    "\n",
    "#originalDir = \"food-101/food-101/images/\"\n",
    "\n",
    "\n",
    "#def scaler(directy):\n",
    "#    print(originalDir + directy)\n",
    "#    image = Image.open(originalDir + directy)\n",
    "#    img = image.resize((256, 256))\n",
    "#\n",
    "#    img.save(ScaledDir + directy)\n",
    "#\n",
    "#for i in range(len(PhotosByCategory)):\n",
    "#   for path in PhotosByCategory[i]:\n",
    "#       #print(path)\n",
    "#       scaler(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_test = [1, 2]\n",
    "y_test = np.array(y_test)\n",
    "y_predicted = [1, 2]\n",
    "y_predicted = np.array(y_predicted)\n",
    "\n",
    "\n",
    "def scores(y_test, y_predicted):\n",
    "\n",
    "    precision = precision_score(y_test, y_predicted)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    auc = np.round(roc_auc_score(y_test, y_predicted), 3)\n",
    "\n",
    "    return precision, recall, accuracy, f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 1</th>\n",
       "      <th>model 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model 1  model 2\n",
       "precision      1.0      1.0\n",
       "recall         1.0      1.0\n",
       "accuracy       1.0      1.0\n",
       "f1 score       1.0      1.0\n",
       "auc            1.0      1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "precision_1, recall_1, accuracy_1, f1_1, auc_1 = scores(y_test, y_predicted)\n",
    "precision_2, recall_2, accuracy_2, f1_2, auc_2 = scores(y_test, y_predicted)\n",
    "data = {'model 1': [precision_1, recall_1, accuracy_1, f1_1, auc_1], 'model 2': [\n",
    "    precision_2, recall_2, accuracy_2, f1_2, auc_2]}\n",
    "df = pd.DataFrame(data)\n",
    "df_new = df.rename(index={0: 'precision', 1: 'recall',\n",
    "                   2: 'accuracy', 3: 'f1 score', 4: 'auc'})\n",
    "df_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our model is being used to find out what food someone is looking at, if we return a badly classified result then this would normally be okay as the user would know not to fully rely on a model that could predict wrong. But in one severe case, some people's cultures pride themselves on their food and having someone learn the incorrect food and tell someone of that culture that their food is actually something else (the wrong classification our model gave) then this could offend and disrespect said cultures. As such we need to ensure our model has high accuracy and precision but also let the user of the model know that the model is not perfect and should not think all returned classification values are final.\n",
    "\n",
    "To avoid any problems from unintended issues, we intend to try to fix such issues by allowing for our model to be reviewed by people and raise issues that we may have unforeseen. Upon acknowledgement of such issues, we will review the model and think of solutions that we can implement that will change the model that will solve the issue but at the same time return accurate results.\n",
    "\n",
    "To make sure we are considering ethics, we will attempt to create a checklist that will ensure that all ethical implications are understood and therefore minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Team Expectation 1*: Communicate with other team members in case of delays to our work\n",
    "* *Team Expectation 2*: Work on assigned work in a timely manner\n",
    "* *Team Expecation 3*: Ensure work is assigned evenly\n",
    "* *Team Expecation 4*: Ask for help always when needed\n",
    "* *Team Expecation 5*: Try to finish work a day before its due to ensure no late turn in deduction.\n",
    "* *Team Expecation 6*: If needed, we will vote on decisions as we develop this project.\n",
    "* *Team Expecation 7*: If in case of conflict, we should attempt to resolve it by holding a conversation with the whole group and ensure everybody is understood.\n",
    "\n",
    "**Individual Expectations**:\n",
    "\n",
    "Joshua: EDA & data visualization, final paper.(results and discussion)\n",
    "\n",
    "Ryan: Algorithm selection, model selection, final paper.(abrstract & problem)\n",
    "\n",
    "Rey: EDA, data preprocessing, final paper.(methods)\n",
    "\n",
    "Terence: Model selection, algorithm selection, final paper.(problem & methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE THE PROPOSAL TIMELINE ACCORDING TO WHAT HAS ACTUALLY HAPPENED AND HOW IT HAS EFFECTED YOUR FUTURE PLANS\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| 4/8  |  1 PM | Passively think of good ideas, topics of interest. \n",
    "\n",
    "| 4/20  |  10 AM |  Search for datasets, brainstorm project ideas. | Choose final dataset and idea.(all) | \n",
    "\n",
    "| 4/24  | 6 PM  | Submit final proposal.  | Divide workload among group members.(all)   |\n",
    "\n",
    "| 5/10  | 2 PM  | Examine datset characteristics and structure.|EDA and Wrangling/preprocessing if necessary(Joshua and Terence) |\n",
    "\n",
    "| 5/19  | 2 PM  | Reserach which algorithms to try. | Algorithm selection. SVM vs CNN. Compare F1 score, misclassification error, and compuatational expense.(all) |\n",
    "\n",
    "| 5/25  | 2 PM  | Begin paper. | Final model selection. Optimize hyperparameters with cross validation. Discussion of results and final evaluation(all) |\n",
    "\n",
    "| 6/8  | Before 11:59 PM  | Proofread and finalize paper. Complete code annotations and polish the  JupyterNotebook(all) | Turn in Final Project!  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43b328d8ee08ef5c8dd037e214af0d89062a936209ea5ccf4632c478dc85c150"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
