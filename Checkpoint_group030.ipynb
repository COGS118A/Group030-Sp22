{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "- Joshua Garcia\n",
    "- Rey Mendoza\n",
    "- Ryan Burden\n",
    "- Terence Ting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The purpose of this project is to select and optimize a model that is appropriate for the task of classifying pictures of food with varying degrees of noise into food categories. Our models will be evaluated by classification error metrics. The datapoint, 'food101' consists 101,000 labeled images of food. Each datapoint has the dimensionality (256, 256, 3), as each image is 256 x 256 in resolution has has three color channels. We will be training supervised classification methods such as random forests, as well as neural network architectures such as ResNet50 on these images and evaluating their performance on the test set. The optimal hyperparameters and architecture of our model will be determied with cross-validated error. Finally, test set precision and recall will be used to evlauate the performance of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "This dataset of food images was previously used by Bossard <i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote) in a similar food image classification study where they sought to automatically recognize pictured dishes using Random Forests to discriminate between key areas of the images, allowing them to classify different parts of the image simultaneously. There, they detailed how classical approaches to image classification use interest point descriptors before being transformed into a vectorial-representation of the image and using Support Vector Machines for classification. They also bring to attention the novel technique of classifying certain objects or parts of an image by using Deformable Part-based Models for object detection <a name=\"felzenszwalb\"></a>[<sup>[2]</sup>](#felzenszwalbnote).\n",
    "\n",
    "Focusing instead on the food recognition part of the paper, they reference a paper by Joutou <a name = \"joutou\"></a>[<sup>[3]</sup>](#joutounote) which used a private dataset of Japanese dishes for training and classification whereas Kawano <a name = \"kawano\"></a>[<sup>[4]</sup>](#kawanonote), while also using a private dataset of Chinese dishes, made use of DPM to locally pool features to aid in food categorization. Furthermore, in a paper by Yang <i>et al</i>. <a name = \"yang\"></a>[<sup>[5]</sup>](#yangnote), the goal was to use images of food and learn the spatial relationships between the different ingredients in the dish using pairwise features. Bossard et al. commented that this particular approach would only be feasible for meals with a standardized layout. \n",
    "\n",
    "As presented by Bossard <i>et al</i>.<i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote), the problem of food classification becomes increasingly relevant given the “abundance of food photography in social networks”. From mundane tasks such as the organization of a collection of food photos to tasks such as helping patients with diabetes easily track and count their calorie intake <i>et al</i>.<a name=\"bossard\"></a>[<sup>[1]</sup>](#bossardnote), classifying images of food has many use cases in today’s society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "For those not well-versed in the culinary arts, identifying and naming different dishes, especially with the prevalence of food across social media, may serve as a challenge. We aim to train some machine learning algorithm to recognize and classify the images of food in this repository so that the algorithm can, with some level of accuracy, correctly classify new images that are input by the user. The success of this machine learning algorithm would be determined by the proportion of images it correctly classifies.\n",
    "\n",
    "In contrast, others might use image classification to perform facial recognition or facial detection in an image which essentially uses features to make decisions on the given image. In our case we would use similar methods to try to detect features from images of food. \n",
    "\n",
    "This problem also faces the issue of non-linearity. Since this is an image which has various forms of noise as well as images taken from different angles and shapes we face the consequence of non-linear data. Meaning our model complexity would increase due to the variable extra handling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "We plan on using the Food-101 Dataset. \n",
    "\n",
    "- https://www.kaggle.com/datasets/dansbecker/food-101?select=food-101.zip\n",
    "- 101 Different food categories, each category of food has various different variations of that food image. In total there are 101,000 images each photo ranges from 384 - 512x384 - 512 pixels. We are given 750 training images as well.\n",
    "- An observation is a photo of a specific type of food\n",
    "- Each category of food is considered its own variable, the photos are stored by their category of food and labled the count of which photo they are. ie.(Pizza_1).\n",
    "- Transformations and images are already centered and properly organized and labled such that we won’t need to take extra special data cleaning to manage this dataset. That said, we do plan on adding extra distortion to these images to test our algorithms accuracy with images that have distortion such as gaussian blur, extra noise, or discoloration.\n",
    "-Each image class will have the same number of images compared to every other class, that is 1000 images per class in order to ensure that each image class is balanced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "Our proposed solution would be to use a deep learning model, Support Vector Machines, and K-Nearest Neighbors in three different image classification models and compare their overall performance when trained on our repository of photos. The paper we based our project on instead uses a Random Forests model to achieve an accuracy of 54-58%. \n",
    "\n",
    "We are considering applying ResNet50, which is a deep learning model with that is used for image classification with relatively high accuracy. Using 48 convolution layers and pretrained over 1 million images from the imageNet database allows the model to classify images into 1000 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "The best evaluation metrics to perform when doing classification are accuracy, precision, and recall. We will find accuracy by dividing the number of predicted class by the number of actual correct in the class. This will give us how well our model predicts the right answer. The precision metric will allow us to see if our model is making too many false positives or false negatives, and is given by dividing the number of true positive by the total predicted positive. Then we use recall metric to find the true predicted positive divided by the total actual positive. We would also like to use an F1 score so that we can see which model contains the highest precision and highest recall to evaluate each model. We can also use the AUC-ROC method where we plot the true positive rate vs the false positive rate and get the area under the curve. The higher the area we get, the better the overall model performance. We can then compare the area amongst the models we select for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "Disclaimer*\n",
    "We have not done any analysis of model accuracy with our dataset yet, this is due to the fact that we need to perform more research on how to impliment the models on image data, we also want to ensure that our models are done correctly to make sure our results come out accurate. \n",
    "\n",
    "We plan on meeting with TA's to further discuss the correct course of action to help us design our models. \n",
    "\n",
    "Although we have not done model accuracy testing yet, we have completed our EDA and we have designed our features that we expect to use from our data. and we have designed our validation accuracy algorithm as shown below. We just need to impliment the models to provide data to our validation code. \n",
    "\n",
    "Also note* All of our code is in the notebook cogs118AProj.ipynb. We have included code snippits here to make it easier to read for the grader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling/ Cleaning\n",
    "\n",
    "This code below is to scale each image to the size 256 x 256. That way we are able to ensure that all of our data is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ScaledDir = \"food-101/food-101/imagesScaled/\"\n",
    "\n",
    "#for cat in categories:\n",
    "#    try:\n",
    "#        os.makedirs(ScaledDir + '/' + cat + '/')\n",
    "#    except:\n",
    "#        donothing = 0\n",
    "#Scale Images\n",
    "#from PIL import Image, ImageStat\n",
    "\n",
    "#originalDir = \"food-101/food-101/images/\"\n",
    "\n",
    "\n",
    "#def scaler(directy):\n",
    "#    print(originalDir + directy)\n",
    "#    image = Image.open(originalDir + directy)\n",
    "#    img = image.resize((256, 256))\n",
    "#\n",
    "#    img.save(ScaledDir + directy)\n",
    "#\n",
    "#for i in range(len(PhotosByCategory)):\n",
    "#   for path in PhotosByCategory[i]:\n",
    "#       #print(path)\n",
    "#       scaler(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA\n",
    "\n",
    "Here we demonstrate our data analysis. At the bottom you will see our findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Average color\n",
    "#def avgColor(directory):\n",
    "#    src_img = cv2.imread(directory)\n",
    "#    average_color_row = np.average(src_img, axis=0)\n",
    "#    average_color = np.average(average_color_row, axis=0)\n",
    "#    r = average_color[0]\n",
    "#    g = average_color[1]\n",
    "#    b = average_color[2]\n",
    "#    return r,g,b\n",
    "\n",
    "#Dont run this code. Takes 15 minutes to run. Images have been generated and saved Shown below.\n",
    "#rVals = []\n",
    "#gVals = []\n",
    "#bVals = []\n",
    "#dir = \"food-101/food-101/images/\"\n",
    "#for itr in range(len(PhotosByCategory)):\n",
    "#    for direct in PhotosByCategory[itr]:\n",
    "#        #print(dir + direct)\n",
    "#        r, g, b = avgColor(dir + direct)\n",
    "#        rVals.append(r)\n",
    "#        gVals.append(g)\n",
    "#        bVals.append(b)\n",
    "from IPython.display import Image\n",
    "\n",
    "#Color distributions\n",
    "#Red\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(rVals, bins=10100)\n",
    "#pyplot.show()\n",
    "#Image(filename='Red.png')\n",
    "#Green\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(gVals, bins=10100)\n",
    "#pyplot.show()\n",
    "#Image(filename='Green.png')\n",
    "#blue\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(bVals, bins=10100)\n",
    "#pyplot.show()\n",
    "#Image(filename='Blue.png')\n",
    "#def brightness(im_file):\n",
    "#   im = Image.open(im_file).convert('L')\n",
    "#   stat = ImageStat.Stat(im)\n",
    "#   im.close\n",
    "#   return stat.rms[0]\n",
    "#Some EDA\n",
    "#PhotosByCategoryLength = len(PhotosByCategory)\n",
    "#NumPhotosByCategory = len(PhotosByCategory[0])\n",
    "#TrainingDataLength = len(trainData)\n",
    "#TestDataLength = len(testData)\n",
    "#totalNumPhotos = TrainingDataLength + TestDataLength\n",
    "\n",
    "#print(\"Total number of categories: \" + str(PhotosByCategoryLength))\n",
    "#print(\"Total number of photos per category: \" + str(NumPhotosByCategory))\n",
    "#print(\"Total number of training data images: \" + str(TrainingDataLength))\n",
    "#print(\"Total number of test data images: \" + str(TestDataLength))\n",
    "#print(\"Total number of photos: \" + str(totalNumPhotos))\n",
    "\n",
    "#avgBrightness = 0\n",
    "#for i in range(TrainingDataLength):\n",
    "#    avgBrightness = brightness(dir + trainData[i]) + avgBrightness\n",
    "#for b in range(TestDataLength):\n",
    "#    avgBrightness = brightness(dir + testData[b]) + avgBrightness\n",
    "#lum = avgBrightness/totalNumPhotos\n",
    "\n",
    "#print(\"The average degreee of luminance is: 133.24769382799204 SI units, Note this number was generated before however the runtime was very long. The code has been commented out for runtime.\")\n",
    "\n",
    "#print(\"Our test to training ration is: \" + str(len(testData)/len(trainData)))\n",
    "\n",
    "\n",
    "#print(\"Categories List: \" + Categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='Red.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='Green.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='Blue.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the images above you'll notice three histograms that show the range of the 10100 images that we have and their average color channels. Youll notice that there are various images that widely range from different colors such that it would present a bit of a challenge for us to use color data to make classifications. From this analysis we learn that we would be better off using greyscale to do our analysis to avoid introducing extra noise in our model selection. Especially when observing the extreme outliars in some images where the distribution isn't completely even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of categories: 101\n",
    "\n",
    "Total number of photos per category: 1000\n",
    "\n",
    "Total number of training data images: 75750\n",
    "\n",
    "Total number of test data images: 25250\n",
    "\n",
    "Total number of photos: 101000\n",
    "\n",
    "The average degreee of luminance is: 133.24769382799204 SI units, Note this number was generated before however the runtime was very long. The code has been commented out for runtime.\n",
    "\n",
    "Our test to training ration is: 0.3333333333333333\n",
    "\n",
    "Categories List: apple_pie, baby_back_ribs, baklava, beef_carpaccio, beef_tartare, beet_salad, beignets, bibimbap, bread_pudding, breakfast_burrito, bruschetta, caesar_salad, cannoli, caprese_salad, carrot_cake, ceviche, cheesecake, cheese_plate, chicken_curry, chicken_quesadilla, chicken_wings, chocolate_cake, chocolate_mousse, churros, clam_chowder, club_sandwich, crab_cakes, creme_brulee, croque_madame, cup_cakes, deviled_eggs, donuts, dumplings, edamame, eggs_benedict, escargots, falafel, filet_mignon, fish_and_chips, foie_gras, french_fries, french_onion_soup, french_toast, fried_calamari, fried_rice, frozen_yogurt, garlic_bread, gnocchi, greek_salad, grilled_cheese_sandwich, grilled_salmon, guacamole, gyoza, hamburger, hot_and_sour_soup, hot_dog, huevos_rancheros, hummus, ice_cream, lasagna, lobster_bisque, lobster_roll_sandwich, macaroni_and_cheese, macarons, miso_soup, mussels, nachos, omelette, onion_rings, oysters, pad_thai, paella, pancakes, panna_cotta, peking_duck, pho, pizza, pork_chop, poutine, prime_rib, pulled_pork_sandwich, ramen, ravioli, red_velvet_cake, risotto, samosa, sashimi, scallops, seaweed_salad, shrimp_and_grits, spaghetti_bolognese, spaghetti_carbonara, spring_rolls, steak, strawberry_shortcake, sushi, tacos, takoyaki, tiramisu, tuna_tartare, waffles,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above we display all of the different variables and types of data we will be working with, one significant finding was the luminance rating. We notice that our average luminance of our images is relatively low, moody, making it an extra challenge since our photos on average tend to lean on the darker side. This makes sense since a lot of the images are of darker foods like beef and chocolate which is dark. We also wanted to highlight how much data we will be working with and highlight the challenge that comes with using such a large amount of data.\n",
    "\n",
    "We frequently found that runtime for this data is very long making it harder for us to debug. However this also gives us an advantage. Our test/train split would be very representativie of the data since the dataset is large enough where a 33% split won't impact our averages as much. \n",
    "\n",
    "Finally, from our own analysis in the images, we found that there is quite a bit of noise in the images, such as plate color appearing in images, background noise like tables or forks, and finally the biggest noise being the camera, since the way it was taken was not uniform. Each camera was calibrated differently and each photo was taken from different angles making it essential that we fine tune our models to try and circumvent this noise such as using a gradient.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_test = [1, 2]\n",
    "y_test = np.array(y_test)\n",
    "y_predicted = [1, 2]\n",
    "y_predicted = np.array(y_predicted)\n",
    "\n",
    "\n",
    "def scores(y_test, y_predicted):\n",
    "\n",
    "    precision = precision_score(y_test, y_predicted)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    auc = np.round(roc_auc_score(y_test, y_predicted), 3)\n",
    "\n",
    "    return precision, recall, accuracy, f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 1</th>\n",
       "      <th>model 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model 1  model 2\n",
       "precision      1.0      1.0\n",
       "recall         1.0      1.0\n",
       "accuracy       1.0      1.0\n",
       "f1 score       1.0      1.0\n",
       "auc            1.0      1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "precision_1, recall_1, accuracy_1, f1_1, auc_1 = scores(y_test, y_predicted)\n",
    "precision_2, recall_2, accuracy_2, f1_2, auc_2 = scores(y_test, y_predicted)\n",
    "data = {'model 1': [precision_1, recall_1, accuracy_1, f1_1, auc_1], 'model 2': [\n",
    "    precision_2, recall_2, accuracy_2, f1_2, auc_2]}\n",
    "df = pd.DataFrame(data)\n",
    "df_new = df.rename(index={0: 'precision', 1: 'recall',\n",
    "                   2: 'accuracy', 3: 'f1 score', 4: 'auc'})\n",
    "df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_78444/1464016876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplot_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_1 = plot_roc_curve(model_1, X_test, y_test)\n",
    "plot_1\n",
    "plot_2 = plot_roc_curve(model_2, X_test, y_test)\n",
    "plot_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve plot\n",
    "size, y_train, y_test = learning_curve(\n",
    "    model, X, y, cv=10, scoring='accuracy', n_jobs=-1, size=len(X))\n",
    "\n",
    "y_train_mean = np.mean(y_train, axis=1)\n",
    "y_test_mean = np.mean(y_test, axis=1)\n",
    "\n",
    "plt.plot(size, train_mean, '--', color=\"#1\",  label=\"Training score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our model is being used to find out what food someone is looking at, if we return a badly classified result then this would normally be okay as the user would know not to fully rely on a model that could predict wrong. But in one severe case, some people's cultures pride themselves on their food and having someone learn the incorrect food and tell someone of that culture that their food is actually something else (the wrong classification our model gave) then this could offend and disrespect said cultures. As such we need to ensure our model has high accuracy and precision but also let the user of the model know that the model is not perfect and should not think all returned classification values are final.\n",
    "\n",
    "To avoid any problems from unintended issues, we intend to try to fix such issues by allowing for our model to be reviewed by people and raise issues that we may have unforeseen. Upon acknowledgement of such issues, we will review the model and think of solutions that we can implement that will change the model that will solve the issue but at the same time return accurate results.\n",
    "\n",
    "To make sure we are considering ethics, we will attempt to create a checklist that will ensure that all ethical implications are understood and therefore minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Team Expectation 1*: Communicate with other team members in case of delays to our work\n",
    "* *Team Expectation 2*: Work on assigned work in a timely manner\n",
    "* *Team Expecation 3*: Ensure work is assigned evenly\n",
    "* *Team Expecation 4*: Ask for help always when needed\n",
    "* *Team Expecation 5*: Try to finish work a day before its due to ensure no late turn in deduction.\n",
    "* *Team Expecation 6*: If needed, we will vote on decisions as we develop this project.\n",
    "* *Team Expecation 7*: If in case of conflict, we should attempt to resolve it by holding a conversation with the whole group and ensure everybody is understood.\n",
    "\n",
    "**Individual Expectations**:\n",
    "\n",
    "Joshua: EDA & data visualization, final paper.(results and discussion)\n",
    "\n",
    "Ryan: Algorithm selection, model selection, final paper.(abrstract & problem)\n",
    "\n",
    "Rey: EDA, data preprocessing, final paper.(methods)\n",
    "\n",
    "Terence: Model selection, algorithm selection, final paper.(problem & methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| 4/8  |  1 PM | Passively think of good ideas, topics of interest. \n",
    "\n",
    "| 4/20  |  10 AM |  Search for datasets, brainstorm project ideas. | Choose final dataset and idea.(all) | \n",
    "\n",
    "| 4/24  | 6 PM  | Submit final proposal.  | Divide workload among group members.(all)   |\n",
    "\n",
    "| 5/10  | 2 PM  | Examine datset characteristics and structure.|EDA and Wrangling/preprocessing if necessary(Joshua and Terence) |\n",
    "\n",
    "| 5/19  | 2 PM  | Reserach which algorithms to try. | Algorithm selection. SVM vs CNN. Compare F1 score, misclassification error, and compuatational expense.(all) |\n",
    "\n",
    "| 5/25  | 2 PM  | Begin paper. | Final model selection and validation. Optimize hyperparameters with cross validation. Discussion of results and final evaluation(all) |\n",
    "\n",
    "| 6/8  | Before 11:59 PM  | Proofread and finalize paper. Complete code annotations and polish the  JupyterNotebook(all) | Turn in Final Project!  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"bossardnote\"></a>1.[^](#bossard): Bossard <i>et al</i>. (Sep 2014) Food-101 - Mining Discriminative Components with Random Forests. https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf<br>\n",
    "<a name=\"felzenszwalbnote\"></a>2. [^](#felzenszwalb): Felzenszwalb, P.F., Girshick, R., McAllester, D., Ramanan, D.: Object detection\n",
    "with discriminatively trained part based models. PAMI (2010)<br>\n",
    "<a name=\"joutounote\"></a>3. [^](#joutou): Joutou, T., Yanai, K.: A food image recognition system with Multiple Kernel Learning. In: ICIP (2009)<br>\n",
    "<a name=\"kawanonote\"></a>4. [^](#kawano): Kawano, Y., Yanai, K.: Real-Time Mobile Food Recognition System. In: IEEE Conference on Computer Vision and Pattern Recognition Workshops (2013)<br>\n",
    "<a name=\"yangnote\"></a>5. [^](#yang): Yang, S.L., Chen, M., Pomerleau, D., Sukthankar, R.: Food recognition using statistics of pairwise local features. In: CVPR (2010)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43b328d8ee08ef5c8dd037e214af0d89062a936209ea5ccf4632c478dc85c150"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
