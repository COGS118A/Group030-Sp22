{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#python -m pip install -U scikit-image\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from skimage.io import imread\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure the food directory is in the same folder as this code\n",
    "dir = \"food-101/food-101/images/\"\n",
    "categories = os.listdir(dir)\n",
    "PhotosByCategory = []\n",
    "Categories = \"\"\n",
    "for b in os.listdir(dir):\n",
    "    if(b != '.DS_Store'):\n",
    "        Categories = Categories + str(b) + \", \"\n",
    "        photos = []\n",
    "        for a in os.listdir(dir + b):\n",
    "            photos.append(b + \"/\" + a)\n",
    "        PhotosByCategory.append(photos)\n",
    "print(len(PhotosByCategory[1]))\n",
    "#photosByCategory contains all categories by number ie. PhotosByCategory[0] = apple_pie directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = \"food-101/food-101/meta/test.txt\"\n",
    "with open(testdir) as f:\n",
    "    lines = f.readlines()\n",
    "testData = []\n",
    "for line in lines:\n",
    "    removed = line.replace(\"\\n\", \"\")\n",
    "    imgDir = removed + '.jpg'\n",
    "\n",
    "    testData.append(imgDir)\n",
    "len(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = \"food-101/food-101/meta/train.txt\"\n",
    "with open(traindir) as f:\n",
    "    lines = f.readlines()\n",
    "trainData = []\n",
    "for line in lines:\n",
    "    removed = line.replace(\"\\n\", \"\")\n",
    "    imgDir = removed + '.jpg'\n",
    "    trainData.append(imgDir)\n",
    "\n",
    "len(trainData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imOpen(path):\n",
    "    imPath = dir + path\n",
    "    img = mpimg.imread(imPath)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image test\n",
    "#Should display an apple pie\n",
    "img2 = imOpen(PhotosByCategory[0][0])\n",
    "plt.imshow(img2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScaledDir = \"food-101/food-101/imagesScaled/\"\n",
    "\n",
    "#for cat in categories:\n",
    "#    try:\n",
    "#        os.makedirs(ScaledDir + '/' + cat + '/')\n",
    "#    except:\n",
    "#        donothing = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Images\n",
    "#from PIL import Image, ImageStat\n",
    "\n",
    "#originalDir = \"food-101/food-101/images/\"\n",
    "\n",
    "\n",
    "#def scaler(directy):\n",
    "#    print(originalDir + directy)\n",
    "#    image = Image.open(originalDir + directy)\n",
    "#    img = image.resize((256, 256))\n",
    "#\n",
    "#    img.save(ScaledDir + directy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#for i in range(len(PhotosByCategory)):\n",
    "#   for path in PhotosByCategory[i]:\n",
    "#       #print(path)\n",
    "#       scaler(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Average color\n",
    "#def avgColor(directory):\n",
    "#    src_img = cv2.imread(directory)\n",
    "#    average_color_row = np.average(src_img, axis=0)\n",
    "#    average_color = np.average(average_color_row, axis=0)\n",
    "#    r = average_color[0]\n",
    "#    g = average_color[1]\n",
    "#    b = average_color[2]\n",
    "#    return r,g,b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont run this code. Takes 15 minutes to run. Images have been generated and saved Shown below.\n",
    "#rVals = []\n",
    "#gVals = []\n",
    "#bVals = []\n",
    "#dir = \"food-101/food-101/images/\"\n",
    "#for itr in range(len(PhotosByCategory)):\n",
    "#    for direct in PhotosByCategory[itr]:\n",
    "#        #print(dir + direct)\n",
    "#        r, g, b = avgColor(dir + direct)\n",
    "#        rVals.append(r)\n",
    "#        gVals.append(g)\n",
    "#        bVals.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "#Color distributions\n",
    "#Red\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(rVals, bins=10100)\n",
    "#pyplot.show()\n",
    "Image(filename='Red.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Green\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(gVals, bins=10100)\n",
    "#pyplot.show()\n",
    "Image(filename='Green.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blue\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.hist(bVals, bins=10100)\n",
    "#pyplot.show()\n",
    "Image(filename='Blue.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def brightness(im_file):\n",
    "#   im = Image.open(im_file).convert('L')\n",
    "#   stat = ImageStat.Stat(im)\n",
    "#   im.close\n",
    "#   return stat.rms[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some EDA\n",
    "PhotosByCategoryLength = len(PhotosByCategory)\n",
    "NumPhotosByCategory = len(PhotosByCategory[0])\n",
    "TrainingDataLength = len(trainData)\n",
    "TestDataLength = len(testData)\n",
    "totalNumPhotos = TrainingDataLength + TestDataLength\n",
    "\n",
    "print(\"Total number of categories: \" + str(PhotosByCategoryLength))\n",
    "print(\"Total number of photos per category: \" + str(NumPhotosByCategory))\n",
    "print(\"Total number of training data images: \" + str(TrainingDataLength))\n",
    "print(\"Total number of test data images: \" + str(TestDataLength))\n",
    "print(\"Total number of photos: \" + str(totalNumPhotos))\n",
    "\n",
    "#avgBrightness = 0\n",
    "#for i in range(TrainingDataLength):\n",
    "#    avgBrightness = brightness(dir + trainData[i]) + avgBrightness\n",
    "#for b in range(TestDataLength):\n",
    "#    avgBrightness = brightness(dir + testData[b]) + avgBrightness\n",
    "#lum = avgBrightness/totalNumPhotos\n",
    "\n",
    "print(\"The average degreee of luminance is: 133.24769382799204 SI units, Note this number was generated before however the runtime was very long. The code has been commented out for runtime.\")\n",
    "\n",
    "print(\"Our test to training ration is: \" + str(len(testData)/len(trainData)))\n",
    "\n",
    "\n",
    "print(\"Categories List: \" + Categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = open('food-101/food-101/meta/classes.txt').read().split()\n",
    "categories\n",
    "\n",
    "test = json.load(open('food-101/food-101/meta/test.json'))\n",
    "train = json.load(open('food-101/food-101/meta/train.json'))\n",
    "\n",
    "count_test = np.array(list(test.values()))\n",
    "print('Number of Test Images:', count_test.shape[0] * count_test.shape[1])\n",
    "\n",
    "count_train = np.array(list(train.values()))\n",
    "print('Number of Train Images:', count_train.shape[0] * count_train.shape[1])\n",
    "\n",
    "whole = {}\n",
    "for key in test.keys():\n",
    "    whole[key] = test[key]\n",
    "    whole[key] += train[key]\n",
    "\n",
    "count_whole = np.array(list(whole.values()))\n",
    "print('Total Number of Images:',\n",
    "      count_whole.shape[0] * count_whole.shape[1], '\\n')\n",
    "\n",
    "print('Number of categories:', len(categories))\n",
    "print('Number of photos per category:', len(whole['apple_pie']))\n",
    "print('List of categories:', categories)\n",
    "\n",
    "plt.imshow(imOpen(train[categories[0]][0] + '.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Dataset')\n",
    "print('Example Keys:', list(train.keys())[:5])\n",
    "print('Example Values:', train['churros'][:5])\n",
    "print('\\nTest Dataset')\n",
    "print('Example Keys:', list(test.keys())[:5])\n",
    "print('Example Values:', test['churros'][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET IS TOO LARGE AHHH\n",
    "#TIME TO RANDOM SAMPLE\n",
    "#Select number of images to be random sampled\n",
    "randomSampleCount = 50\n",
    "\n",
    "random.seed(255)\n",
    "sequence = [i for i in range(1000)]\n",
    "randList = random.sample(sequence, randomSampleCount)\n",
    "\n",
    "randomSampled = []\n",
    "scaleddir = 'food-101/food-101/imagesScaled/'\n",
    "for cat in categories:\n",
    "    directory = scaleddir + cat\n",
    "    path = os.listdir(directory)\n",
    "    index = 0\n",
    "    imagesToBeSampled = []\n",
    "    for images in path:\n",
    "        index = index + 1\n",
    "        if(index in randList):\n",
    "            imagesToBeSampled.append(images)\n",
    "    randomSampled.append(imagesToBeSampled)\n",
    "print(randomSampled[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM WORK\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "flat = []\n",
    "images2 = []\n",
    "#Resized array ***CRITICAL USE RESIZED ARRAY\n",
    "scaleddir = 'food-101/food-101/imagesScaled/'\n",
    "\n",
    "#This gets all images and puts them into a dataframe\n",
    "#DESIGN NOTES\n",
    "#Changes image size to 50x50 due to processign speed. 250x250 increases processing time by 30% which scales exponentially.\n",
    "index = 0\n",
    "for cat in categories:\n",
    "    directory = scaleddir + cat    \n",
    "    path = randomSampled[index]\n",
    "    index = index + 1\n",
    "    for images in path:\n",
    "        toArr = imread(os.path.join(directory, images))\n",
    "        img_resized = resize(toArr, (50, 50, 3))\n",
    "        flat.append(img_resized.flatten())\n",
    "        images2.append(Categories.index(cat))\n",
    "flattened = np.array(flat)\n",
    "images_arr = np.array(images2)\n",
    "df = pd.DataFrame(flattened)\n",
    "df['Target'] = images_arr\n",
    "\n",
    "#Here we create our test to data split\n",
    "#Default is 30\n",
    "ts = .30\n",
    "rs = 45\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=ts, random_state=rs, stratify=y)\n",
    "\n",
    "#Next we scale the data. This is to improve processing time and does not affect the quality of our data. Some what of a hack with SVM.\n",
    "#Note without this we can observe a 20% increase in processin time.\n",
    "scaling = MinMaxScaler(feature_range=(-1, 1)).fit(x_train)\n",
    "x_train = scaling.transform(x_train)\n",
    "x_test = scaling.transform(x_test)\n",
    "print(\"Number of training data: \" + str(len(x_train)))\n",
    "print(\"Number of testing data: \" + str(len(x_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is our svm model.\n",
    "params = {'C': [10], 'gamma': [0.0001], 'kernel': ['rbf']}\n",
    "svm = svm.SVC(probability=True)\n",
    "print(\"Please wait...\")\n",
    "model = GridSearchCV(svm, params)\n",
    "model.fit(x_train, y_train)\n",
    "print('The Model is trained well with the given images')\n",
    "model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"SVM's accuracy is {accuracy_score(y_pred,y_test)*100}%\")\n",
    "\n",
    "#Average accuracy for the model using SVM is:\n",
    "\n",
    "#Saves our model so we dont have to process again.\n",
    "pickle.dump(model, open('svmModel.p', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
